{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fea3bd15",
   "metadata": {},
   "source": [
    "## Phase 2: Flow Control & Logic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f54f7a",
   "metadata": {},
   "source": [
    "##### Conditional Branching (Decision Making)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6940998b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# A Decider Node\n",
    "def decide_next_step(state: GraphState) -> str:\n",
    "    if \"math\" in state[\"user_input\"].lower():\n",
    "        print(\"--- Decision: Math keyword detected. Going to Calculator.\")\n",
    "        return \"calculator_tool\"\n",
    "    elif \"factual\" in state[\"user_input\"].lower():\n",
    "        print(\"--- Decision: Factual keyword detected. Going to Search.\")\n",
    "        return \"search_tool\"\n",
    "    else:\n",
    "        print(\"--- Decision: Chat/General query. Going to LLM Chat.\")\n",
    "        return \"llm_chat\"\n",
    "\n",
    "# ... assuming nodes 'calculator_tool', 'search_tool', and 'llm_chat' are defined ...\n",
    "\n",
    "workflow.add_node(\"decider\", decide_next_step)\n",
    "\n",
    "# workflow.add_conditional_edges(source, condition_function, mapping)\n",
    "\n",
    "# Use add_conditional_edges\n",
    "workflow.add_conditional_edges(\n",
    "    # Source node that makes the decision\n",
    "    \"decider\", \n",
    "    # The function that is the decider (it MUST return the name of the next node)\n",
    "    decide_next_step, \n",
    "    # Optional: Map the string output to the target node name\n",
    "    {\n",
    "        \"calculator_tool\": \"calculator_tool\",\n",
    "        \"search_tool\": \"search_tool\",\n",
    "        \"llm_chat\": \"llm_chat\",\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b0b56a",
   "metadata": {},
   "source": [
    "##### Tools & Functions Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833cac8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "# 1. Define the tool\n",
    "search_tool = TavilySearchResults(max_results=3)\n",
    "tools = [search_tool]\n",
    "\n",
    "# 2. Create the special ToolNode\n",
    "# This node takes a tool call from the LLM, executes it, and updates the state.\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "# 3. Add to the graph\n",
    "# workflow.add_node(\"search_tool_executor\", tool_node) \n",
    "# (Assuming we have a node that generates the tool call)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "2d77a6cc",
   "metadata": {},
   "source": [
    "this is the core of agentic workflows!\n",
    "Without tools, agents are just fancy chatbots ‚Äî but with tools, they become intelligent assistants that can act in the real world.\n",
    "\n",
    "So yes, we‚Äôll go step by step, starting from the simplest possible tool, and gradually move to:\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd75490",
   "metadata": {},
   "source": [
    "> üå± Phase 1 ‚Äî The Simplest Tool: Custom Python Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fb11045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# without any APIs, just a pure Python tool, \n",
    "# so you can see how tool calling logic works under the hood.\n",
    "\n",
    "from langchain.tools import tool\n",
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "# 1Ô∏è‚É£ Define the tool\n",
    "@tool\n",
    "def add_numbers(a: int, b: int) -> int:\n",
    "    \"\"\"Adds two numbers and returns the sum.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "# 2Ô∏è‚É£ Create LLM\n",
    "llm = ChatOllama(\n",
    "    model=\"gpt-oss:120b-cloud\"\n",
    ")\n",
    "\n",
    "# 3Ô∏è‚É£ Bind the tools\n",
    "llm_with_tools = llm.bind_tools([add_numbers])\n",
    "\n",
    "# 4Ô∏è‚É£ Create ToolNode\n",
    "tool_node = ToolNode([add_numbers])\n",
    "\n",
    "# 5Ô∏è‚É£ Direct test (optional)\n",
    "print(add_numbers.invoke({\"a\": 3, \"b\": 5}))  # ‚Üí 8\n"
   ]
  },
  {
   "attachments": {
    "image-2.png": {
     "image/png": "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"
    },
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "d0679292",
   "metadata": {},
   "source": [
    "##### ‚öôÔ∏è Goal , We‚Äôll build this tiny graph:\n",
    "\n",
    "![image-2.png](attachment:image-2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12e5dd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_input': 'Add 3 and 7 using add_numbers tool', 'messages': [ToolMessage(content='10', name='add_numbers', tool_call_id='3ad3554f-ef8b-4704-80b4-77638ac60b44')]}\n"
     ]
    }
   ],
   "source": [
    "# 1Ô∏è‚É£ Imports\n",
    "from langchain.tools import tool\n",
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from typing import TypedDict\n",
    "from langchain_core.messages import AIMessage\n",
    "# 2Ô∏è‚É£ Define Graph State\n",
    "class GraphState(TypedDict):\n",
    "    user_input: str\n",
    "    messages: list\n",
    "\n",
    "# 3Ô∏è‚É£ Define the tool\n",
    "@tool\n",
    "def add_numbers(a: int, b: int) -> int:\n",
    "    \"\"\"Adds two numbers and returns the sum.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "# 4Ô∏è‚É£ Define LLM and bind tools\n",
    "llm = ChatOllama(\n",
    "    model=\"gpt-oss:120b-cloud\"\n",
    ")\n",
    "llm_with_tools = llm.bind_tools([add_numbers])\n",
    "\n",
    "# 5Ô∏è‚É£ Define LLM node\n",
    "def call_model(state: GraphState):\n",
    "    # Step 1: prepare messages\n",
    "    user_msg = state[\"user_input\"]\n",
    "\n",
    "    # Step 2: ask model\n",
    "    response = llm_with_tools.invoke(user_msg)\n",
    "\n",
    "    # Step 3: store messages for tool node\n",
    "    return {\"messages\": [response]}  # ‚úÖ send as list\n",
    "\n",
    "# 6Ô∏è‚É£ Define Tool Node\n",
    "tool_node = ToolNode([add_numbers])\n",
    "\n",
    "# 7Ô∏è‚É£ Define workflow\n",
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node(\"llm\", call_model)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "workflow.add_edge(\"llm\", \"tools\")\n",
    "workflow.add_edge(\"tools\", END)\n",
    "workflow.set_entry_point(\"llm\")\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "# 8Ô∏è‚É£ Run\n",
    "result = app.invoke({\"user_input\": \"Add 3 and 7 using add_numbers tool\"}) # type: ignore\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dedfd68",
   "metadata": {},
   "source": [
    ">  2Ô∏è‚É£ Built-in tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fe2fee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_input': \"Search for today's latest news about Donald trump and what he said about his 3rd terms run for presidental election.\", 'messages': [ToolMessage(content='snippet: 1 day ago ¬∑ President Donald Trump appeared to acknowledge Wednesday that he cannot run for a third term , after previously declining to rule out the possibility., title: Trump says \\'it\\'s pretty clear\\' he can\\'t run for 3rd term ..., link: https://abcnews.go.com/Politics/trump-pretty-clear-run-3rd-term/story?id=126968713, snippet: 1 day ago ¬∑ His comments came after House Speaker Mike Johnson stated it would be impossible for Trump to keep serving as president. Johnson explained that the 22nd Amendment prevents a third term and ..., title: Trump says ‚Äòit‚Äôs too bad‚Äô he can‚Äôt run for a third term, link: https://www.pbs.org/newshour/politics/trump-says-its-too-bad-he-cant-run-for-a-third-term, snippet: 1 day ago ¬∑ President Donald Trump has said it is ‚Äúpretty clear‚Äù the US Constitution does not permit him to run for the third term in office., title: Trump third term: President says it‚Äôs ‚Äúpretty clear‚Äù he‚Äôs not ..., link: https://www.cnn.com/2025/10/29/politics/trump-says-clear-no-third-term-intl-hnk, snippet: 1 day ago ¬∑ President Trump appeared to concede Wednesday that he \\'s not allowed to run for reelection in 2028, after teasing the idea on and off for months., title: Trump seems to acknowledge he can\\'t run for a third term: \"It ..., link: https://www.cbsnews.com/news/trump-acknowledges-he-cant-run-for-a-third-term-its-too-bad/', name='duckduckgo_results_json', tool_call_id='4bcccb21-5f5b-4910-836b-f8bd2b1a798c', artifact=[{'snippet': '1 day ago ¬∑ President Donald Trump appeared to acknowledge Wednesday that he cannot run for a third term , after previously declining to rule out the possibility.', 'title': \"Trump says 'it's pretty clear' he can't run for 3rd term ...\", 'link': 'https://abcnews.go.com/Politics/trump-pretty-clear-run-3rd-term/story?id=126968713'}, {'snippet': '1 day ago ¬∑ His comments came after House Speaker Mike Johnson stated it would be impossible for Trump to keep serving as president. Johnson explained that the 22nd Amendment prevents a third term and ...', 'title': 'Trump says ‚Äòit‚Äôs too bad‚Äô he can‚Äôt run for a third term', 'link': 'https://www.pbs.org/newshour/politics/trump-says-its-too-bad-he-cant-run-for-a-third-term'}, {'snippet': '1 day ago ¬∑ President Donald Trump has said it is ‚Äúpretty clear‚Äù the US Constitution does not permit him to run for the third term in office.', 'title': 'Trump third term: President says it‚Äôs ‚Äúpretty clear‚Äù he‚Äôs not ...', 'link': 'https://www.cnn.com/2025/10/29/politics/trump-says-clear-no-third-term-intl-hnk'}, {'snippet': \"1 day ago ¬∑ President Trump appeared to concede Wednesday that he 's not allowed to run for reelection in 2028, after teasing the idea on and off for months.\", 'title': 'Trump seems to acknowledge he can\\'t run for a third term: \"It ...', 'link': 'https://www.cbsnews.com/news/trump-acknowledges-he-cant-run-for-a-third-term-its-too-bad/'}])]}\n"
     ]
    }
   ],
   "source": [
    "# 1Ô∏è‚É£ Imports\n",
    "from langchain_community.tools import DuckDuckGoSearchResults\n",
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from typing import TypedDict\n",
    "\n",
    "# 2Ô∏è‚É£ Define State\n",
    "class GraphState(TypedDict):\n",
    "    user_input: str\n",
    "    messages: list\n",
    "\n",
    "# 3Ô∏è‚É£ Define Tool\n",
    "search_tool = DuckDuckGoSearchResults()\n",
    "\n",
    "# 4Ô∏è‚É£ LLM + Bind\n",
    "llm = ChatOllama(\n",
    "    model=\"gpt-oss:120b-cloud\"\n",
    ")\n",
    "llm_with_tools = llm.bind_tools([search_tool])\n",
    "\n",
    "# 5Ô∏è‚É£ LLM Node\n",
    "def call_model(state: GraphState):\n",
    "    response = llm_with_tools.invoke(state[\"user_input\"])\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# 6Ô∏è‚É£ Tool Node\n",
    "tool_node = ToolNode([search_tool])\n",
    "\n",
    "# 7Ô∏è‚É£ Graph\n",
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node(\"llm\", call_model)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "workflow.add_edge(\"llm\", \"tools\")\n",
    "workflow.add_edge(\"tools\", END)\n",
    "workflow.set_entry_point(\"llm\")\n",
    "app = workflow.compile()\n",
    "\n",
    "# 8Ô∏è‚É£ Run\n",
    "result = app.invoke({\"user_input\": \"Search for today's latest news about Donald trump and what he said about his 3rd terms run for presidental election.\"}) # type: ignore\n",
    "print(result)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0201d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U ddgs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9709c4b",
   "metadata": {},
   "source": [
    "> 3Ô∏è‚É£ API-based tools ‚Äî the most real-world and powerful type üí™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9a75ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_input': 'Check the weather in Delhi', 'messages': [ToolMessage(content='The current temperature in Delhi is 21.0¬∞C.', name='get_weather', tool_call_id='8115ccd4-0d2d-4d5d-87b6-bf4f3540fce2')]}\n"
     ]
    }
   ],
   "source": [
    "# 1Ô∏è‚É£ Imports\n",
    "from langchain.tools import tool\n",
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from typing import TypedDict\n",
    "import requests\n",
    "\n",
    "# 2Ô∏è‚É£ Define Graph State\n",
    "class GraphState(TypedDict):\n",
    "    user_input: str\n",
    "    messages: list\n",
    "\n",
    "# 3Ô∏è‚É£ Define API Tool\n",
    "@tool\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Fetches current temperature for a given city using Open-Meteo API.\"\"\"\n",
    "    try:\n",
    "        # Get city coordinates\n",
    "        geo_url = f\"https://geocoding-api.open-meteo.com/v1/search?name={city}\"\n",
    "        geo = requests.get(geo_url).json()\n",
    "\n",
    "        if not geo.get(\"results\"):\n",
    "            return f\"City '{city}' not found.\"\n",
    "\n",
    "        lat = geo[\"results\"][0][\"latitude\"]\n",
    "        lon = geo[\"results\"][0][\"longitude\"]\n",
    "\n",
    "        # Get current weather\n",
    "        weather_url = f\"https://api.open-meteo.com/v1/forecast?latitude={lat}&longitude={lon}&current_weather=true\"\n",
    "        weather = requests.get(weather_url).json()\n",
    "        temp = weather[\"current_weather\"][\"temperature\"]\n",
    "\n",
    "        return f\"The current temperature in {city} is {temp}¬∞C.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "# 4Ô∏è‚É£ Define LLM and bind the tool\n",
    "llm = ChatOllama(\n",
    "    model=\"gpt-oss:120b-cloud\"\n",
    ")\n",
    "llm_with_tools = llm.bind_tools([get_weather])\n",
    "\n",
    "# 5Ô∏è‚É£ Define LLM Node\n",
    "def call_model(state: GraphState):\n",
    "    response = llm_with_tools.invoke(state[\"user_input\"])\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# 6Ô∏è‚É£ Define Tool Node\n",
    "tool_node = ToolNode([get_weather])\n",
    "\n",
    "# 7Ô∏è‚É£ Build Graph\n",
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node(\"llm\", call_model)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "workflow.add_edge(\"llm\", \"tools\")\n",
    "workflow.add_edge(\"tools\", END)\n",
    "workflow.set_entry_point(\"llm\")\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "# 8Ô∏è‚É£ Run\n",
    "result = app.invoke({\"user_input\": \"Check the weather in Delhi\"}) # type: ignore\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97213f40",
   "metadata": {},
   "source": [
    "> 4Ô∏è‚É£: Multi-Tool Integration -> (LLM automatically chooses the right tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd59c020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß≠ Asking about weather:\n",
      "{'user_input': \"What's the weather in Delhi right now?\", 'messages': [ToolMessage(content='The current temperature in Delhi is 21.2¬∞C.', name='get_weather', tool_call_id='868e2c4f-0cba-48f8-a91b-cb014b929ac8')]}\n",
      "\n",
      "‚è∞ Asking about time:\n",
      "{'user_input': \"What's the current time in Tokyo?\", 'messages': [ToolMessage(content='The current local time in Tokyo is 2025-10-31 03:06:10.', name='get_time', tool_call_id='e90b3008-1fe7-4026-a0d0-4dc24f6da247')]}\n"
     ]
    }
   ],
   "source": [
    "# 1Ô∏è‚É£ Imports\n",
    "from langchain.tools import tool\n",
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from typing import TypedDict\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "# 2Ô∏è‚É£ Define Graph State\n",
    "class GraphState(TypedDict):\n",
    "    user_input: str\n",
    "    messages: list\n",
    "\n",
    "# 3Ô∏è‚É£ Define Tools\n",
    "@tool\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Fetches current temperature for a given city using Open-Meteo API.\"\"\"\n",
    "    try:\n",
    "        geo = requests.get(f\"https://geocoding-api.open-meteo.com/v1/search?name={city}\").json()\n",
    "        if not geo.get(\"results\"):\n",
    "            return f\"City '{city}' not found.\"\n",
    "        lat, lon = geo[\"results\"][0][\"latitude\"], geo[\"results\"][0][\"longitude\"]\n",
    "        weather = requests.get(f\"https://api.open-meteo.com/v1/forecast?latitude={lat}&longitude={lon}&current_weather=true\").json()\n",
    "        return f\"The current temperature in {city} is {weather['current_weather']['temperature']}¬∞C.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "@tool\n",
    "def get_time(city: str) -> str:\n",
    "    \"\"\"Returns the current local time for a given city.\"\"\"\n",
    "    try:\n",
    "        geo = requests.get(f\"https://geocoding-api.open-meteo.com/v1/search?name={city}\").json()\n",
    "        if not geo.get(\"results\"):\n",
    "            return f\"City '{city}' not found.\"\n",
    "        timezone = geo[\"results\"][0][\"timezone\"]\n",
    "        local_time = datetime.now(pytz.timezone(timezone)).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        return f\"The current local time in {city} is {local_time}.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "# 4Ô∏è‚É£ Define LLM and bind both tools\n",
    "llm = ChatOllama(\n",
    "    model=\"gpt-oss:120b-cloud\"\n",
    ")\n",
    "llm_with_tools = llm.bind_tools([get_weather, get_time])\n",
    "\n",
    "# 5Ô∏è‚É£ Define LLM node\n",
    "def call_model(state: GraphState):\n",
    "    response = llm_with_tools.invoke(state[\"user_input\"])\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# 6Ô∏è‚É£ Define Tool Node\n",
    "tool_node = ToolNode([get_weather, get_time])\n",
    "\n",
    "# 7Ô∏è‚É£ Build Graph\n",
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node(\"llm\", call_model)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "workflow.add_edge(\"llm\", \"tools\")\n",
    "workflow.add_edge(\"tools\", END)\n",
    "workflow.set_entry_point(\"llm\")\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "# 8Ô∏è‚É£ Run examples\n",
    "print(\"\\nüß≠ Asking about weather:\")\n",
    "result1 = app.invoke({\"user_input\": \"What's the weather in Delhi right now?\"}) # type: ignore\n",
    "print(result1)\n",
    "\n",
    "print(\"\\n‚è∞ Asking about time:\")\n",
    "result2 = app.invoke({\"user_input\": \"What's the current time in Tokyo?\"}) # type: ignore\n",
    "print(result2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328f8cb5",
   "metadata": {},
   "source": [
    "> Create multi-step reasoning flow: LLM ‚Üí Decider ‚Üí Tool ‚Üí LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa89e26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-using the tool_node and a decision logic function:\n",
    "\n",
    "# 1. Decision function checks if LLM requested a tool\n",
    "def route_to_tool_or_end(state: GraphState) -> str:\n",
    "    # Simplified logic: if the state has a 'tool_call' key, go to the tool node\n",
    "    if state.get(\"tool_call\"):\n",
    "        return \"tool_node_executor\"\n",
    "    else:\n",
    "        return END\n",
    "\n",
    "# Add nodes and edges..\n",
    "workflow.add_node(\"llm_agent\", llm_node_with_tools) # LLM that can decide to call a tool\n",
    "workflow.add_node(\"tool_node_executor\", tool_node) # Tool executor\n",
    "\n",
    "# Sequential edge to start the decision after the LLM runs\n",
    "workflow.add_edge(\"llm_agent\", \"decide_next_step\") \n",
    "\n",
    "# Conditional edge for the loop\n",
    "workflow.add_conditional_edges(\n",
    "    \"decide_next_step\", \n",
    "    route_to_tool_or_end, \n",
    "    {\"tool_node_executor\": \"tool_node_executor\", END: END}\n",
    ")\n",
    "\n",
    "# Edge back to the LLM (THE LOOP)\n",
    "workflow.add_edge(\"tool_node_executor\", \"llm_agent\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24da30b6",
   "metadata": {},
   "source": [
    "> Loops & Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91307a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_RETRIES = 3\n",
    "\n",
    "def retry_decider(state: GraphState) -> str:\n",
    "    retries = state.get(\"retry_count\", 0)\n",
    "    output_is_valid = state.get(\"is_valid\", False)\n",
    "\n",
    "    if output_is_valid or retries >= MAX_RETRIES:\n",
    "        print(\"--- Loop Exit: Valid output or max retries reached.\")\n",
    "        return END\n",
    "    else:\n",
    "        print(\"--- Loop Back: Invalid output, retrying LLM node.\")\n",
    "        return \"llm_generation_node\"\n",
    "\n",
    "# ... assume 'llm_generation_node' and a 'validation_node' exist ...\n",
    "\n",
    "# Edge from the validation step to the conditional decider\n",
    "workflow.add_edge(\"validation_node\", \"retry_decider\") \n",
    "\n",
    "# Conditional edge routes back to the generator or to END\n",
    "workflow.add_conditional_edges(\n",
    "    \"retry_decider\", \n",
    "    retry_decider, \n",
    "    {\n",
    "        \"llm_generation_node\": \"llm_generation_node\", \n",
    "        END: END\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8173bd6b",
   "metadata": {},
   "source": [
    "> üß† The Concept: ‚ÄúReflect & Act‚Äù Loop (LLM ‚Üí Decider ‚Üí Tool ‚Üí LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cd6ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß© Step-by-Step Implementation (Concept + Code Skeleton)\n",
    "\n",
    "# 1Ô∏è‚É£ Define the Graph State\n",
    "class GraphState(TypedDict):\n",
    "    messages: list\n",
    "    tool_call: dict | None\n",
    "\n",
    "\n",
    "# 2Ô∏è‚É£ LLM Node ‚Äî Think Step\n",
    "def llm_agent_node(state: GraphState):\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    # If the model wants to call a tool, store it\n",
    "    tool_call = getattr(response, \"tool_calls\", None)\n",
    "    return {\"messages\": state[\"messages\"] + [response], \"tool_call\": tool_call}\n",
    "\n",
    "\n",
    "# 3Ô∏è‚É£ Decider Node ‚Äî The Gatekeeper\n",
    "def route_to_tool_or_end(state: GraphState) -> str:\n",
    "    if state.get(\"tool_call\"):\n",
    "        return \"tool_executor\"\n",
    "    else:\n",
    "        return END\n",
    "\n",
    "\n",
    "# 4Ô∏è‚É£ Tool Node ‚Äî Act Step\n",
    "tool_node = ToolNode([search_tool, calculator_tool])\n",
    "\n",
    "\n",
    "# 5Ô∏è‚É£ The Reflective Loop ‚Äî Connect Everything\n",
    "workflow.add_node(\"llm_agent\", llm_agent_node)\n",
    "workflow.add_node(\"decide_next_step\", route_to_tool_or_end)\n",
    "workflow.add_node(\"tool_executor\", tool_node)\n",
    "\n",
    "# sequential edges\n",
    "workflow.add_edge(\"llm_agent\", \"decide_next_step\")\n",
    "\n",
    "# conditional edge ‚Äî decides whether to continue or end\n",
    "workflow.add_conditional_edges(\n",
    "    \"decide_next_step\",\n",
    "    route_to_tool_or_end,\n",
    "    {\"tool_executor\": \"tool_executor\", END: END}\n",
    ")\n",
    "\n",
    "# loop edge ‚Äî once tool finishes, send back to LLM\n",
    "workflow.add_edge(\"tool_executor\", \"llm_agent\")\n",
    "\n",
    "workflow.set_entry_point(\"llm_agent\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f97546b",
   "metadata": {},
   "source": [
    "# ‚úÖ Final Minimal Working Reasoning Agent (with DuckDuckGo + Calculator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dee720fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [\" 'What is the square root of 144?' And ' who founded SpaceX?' \", AIMessage(content='- The square root of **144** is **12**.  \\n- **SpaceX** was founded by **Elon Musk** in 2002.', additional_kwargs={}, response_metadata={'model': 'gpt-oss:120b', 'created_at': '2025-10-30T18:16:01.056720348Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1198164684, 'load_duration': None, 'prompt_eval_count': 196, 'prompt_eval_duration': None, 'eval_count': 68, 'eval_duration': None, 'model_name': 'gpt-oss:120b', 'model_provider': 'ollama'}, id='lc_run--8524ed09-55f9-4612-a8fd-b99b022d4417-0', usage_metadata={'input_tokens': 196, 'output_tokens': 68, 'total_tokens': 264})], 'tool_call': []}\n"
     ]
    }
   ],
   "source": [
    "# 1Ô∏è‚É£ Imports\n",
    "from langchain.tools import tool\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from typing import TypedDict\n",
    "\n",
    "# 2Ô∏è‚É£ Define Graph State\n",
    "class GraphState(TypedDict):\n",
    "    messages: list\n",
    "    tool_call: dict | None\n",
    "\n",
    "# 3Ô∏è‚É£ Tools\n",
    "@tool\n",
    "def calculator_tool(a: float, b: float, op: str = \"add\") -> float:\n",
    "    \"\"\"Simple calculator tool\"\"\"\n",
    "    if op == \"add\":\n",
    "        return a + b\n",
    "    elif op == \"sub\":\n",
    "        return a - b\n",
    "    elif op == \"mul\":\n",
    "        return a * b\n",
    "    elif op == \"div\":\n",
    "        return a / b\n",
    "    else:\n",
    "        return \"Invalid operation\" # type: ignore\n",
    "\n",
    "search_tool = DuckDuckGoSearchRun()\n",
    "\n",
    "\n",
    "# 4Ô∏è‚É£ LLM + tool binding\n",
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Change the model to a known compatible one for tool calling\n",
    "# llm_raw = HuggingFaceEndpoint(\n",
    "#     repo_id=\"HuggingFaceH4/zephyr-7b-beta\",\n",
    "#     task=\"text-generation\"\n",
    "# ) # type: ignore\n",
    "\n",
    "# llm = ChatHuggingFace(llm=llm_raw)\n",
    "\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"gpt-oss:120b-cloud\"\n",
    ")\n",
    "\n",
    "\n",
    "llm_with_tools = llm.bind_tools([calculator_tool, search_tool])\n",
    "\n",
    "# 5Ô∏è‚É£ LLM Node\n",
    "def llm_agent(state: GraphState):\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    tool_call = getattr(response, \"tool_calls\", None)\n",
    "    return {\"messages\": state[\"messages\"] + [response], \"tool_call\": tool_call}\n",
    "\n",
    "# 6Ô∏è‚É£ Tool Node\n",
    "tool_node = ToolNode([calculator_tool, search_tool])\n",
    "\n",
    "# 7Ô∏è‚É£ Decider ‚Äî pure routing function\n",
    "def route_to_tool_or_end(state: GraphState) -> str:\n",
    "    if state.get(\"tool_call\"):\n",
    "        return \"tool_executor\"\n",
    "    else:\n",
    "        return END\n",
    "\n",
    "# 8Ô∏è‚É£ Build Workflow\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "workflow.add_node(\"llm_agent\", llm_agent)\n",
    "workflow.add_node(\"tool_executor\", tool_node)\n",
    "\n",
    "# ‚úÖ Sequential edge: start with LLM\n",
    "workflow.set_entry_point(\"llm_agent\")\n",
    "\n",
    "# ‚úÖ Conditional routing: from LLM ‚Üí tool or END\n",
    "workflow.add_conditional_edges(\n",
    "    \"llm_agent\", route_to_tool_or_end,\n",
    "    {\"tool_executor\": \"tool_executor\", END: END}\n",
    ")\n",
    "\n",
    "# ‚úÖ Loop: After tool ‚Üí back to LLM\n",
    "workflow.add_edge(\"tool_executor\", \"llm_agent\")\n",
    "\n",
    "# 9Ô∏è‚É£ Compile\n",
    "app = workflow.compile()\n",
    "\n",
    "# üîü Run\n",
    "result = app.invoke({\"messages\": [\" 'What is the square root of 144?' And ' who founded SpaceX?' \"]}) # type: ignore\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe351832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a014170",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d55a0c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e97bf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dffd5dea",
   "metadata": {},
   "source": [
    "# till here everything is working fine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1682cad0",
   "metadata": {},
   "source": [
    "# agents 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e71608a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ResponseError",
     "evalue": "Invalid tool usage: mismatch between tool calls and tool results (status code: 400)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mResponseError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 153\u001b[39m\n\u001b[32m    150\u001b[39m app = workflow.compile()\n\u001b[32m    152\u001b[39m \u001b[38;5;66;03m# üîü Run Example\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m result = \u001b[43mapp\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWhat\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43ms the weather in Mumbai and what is 12*8? Also tell time now.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Langgraph\\venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:3094\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3091\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3092\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3094\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3095\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3096\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3097\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3098\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3099\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3100\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3101\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3102\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3103\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3104\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3105\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3106\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3107\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3108\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3109\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Langgraph\\venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:2679\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2677\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2678\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2679\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2680\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2681\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2682\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2683\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2684\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2685\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2686\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2687\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2688\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2689\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Langgraph\\venv\\Lib\\site-packages\\langgraph\\pregel\\_runner.py:167\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    165\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Langgraph\\venv\\Lib\\site-packages\\langgraph\\pregel\\_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Langgraph\\venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:656\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    654\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    658\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Langgraph\\venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:400\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    398\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 88\u001b[39m, in \u001b[36mllm_agent\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mllm_agent\u001b[39m(state: GraphState):\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m     response = \u001b[43mllm_with_tools\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m     tool_call = \u001b[38;5;28mgetattr\u001b[39m(response, \u001b[33m\"\u001b[39m\u001b[33mtool_calls\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     90\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: state[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m] + [response], \u001b[33m\"\u001b[39m\u001b[33mtool_call\u001b[39m\u001b[33m\"\u001b[39m: tool_call}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Langgraph\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5492\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5485\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5486\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5487\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5490\u001b[39m     **kwargs: Any | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   5491\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5492\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5493\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5494\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5495\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5496\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Langgraph\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:379\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    365\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    366\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    367\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    372\u001b[39m     **kwargs: Any,\n\u001b[32m    373\u001b[39m ) -> AIMessage:\n\u001b[32m    374\u001b[39m     config = ensure_config(config)\n\u001b[32m    375\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    376\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    377\u001b[39m         cast(\n\u001b[32m    378\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m379\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    389\u001b[39m         ).message,\n\u001b[32m    390\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Langgraph\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1088\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1079\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1080\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1081\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1085\u001b[39m     **kwargs: Any,\n\u001b[32m   1086\u001b[39m ) -> LLMResult:\n\u001b[32m   1087\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1088\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Langgraph\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:903\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    900\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    901\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    902\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m903\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    904\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    905\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    906\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    907\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    908\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    909\u001b[39m         )\n\u001b[32m    910\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    911\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Langgraph\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1192\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1190\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1191\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1192\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1196\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Langgraph\\venv\\Lib\\site-packages\\langchain_ollama\\chat_models.py:1025\u001b[39m, in \u001b[36mChatOllama._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1018\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate\u001b[39m(\n\u001b[32m   1019\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1020\u001b[39m     messages: \u001b[38;5;28mlist\u001b[39m[BaseMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1023\u001b[39m     **kwargs: Any,\n\u001b[32m   1024\u001b[39m ) -> ChatResult:\n\u001b[32m-> \u001b[39m\u001b[32m1025\u001b[39m     final_chunk = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_chat_stream_with_aggregation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1028\u001b[39m     generation_info = final_chunk.generation_info\n\u001b[32m   1029\u001b[39m     chat_generation = ChatGeneration(\n\u001b[32m   1030\u001b[39m         message=AIMessage(\n\u001b[32m   1031\u001b[39m             content=final_chunk.text,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1038\u001b[39m         generation_info=generation_info,\n\u001b[32m   1039\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Langgraph\\venv\\Lib\\site-packages\\langchain_ollama\\chat_models.py:960\u001b[39m, in \u001b[36mChatOllama._chat_stream_with_aggregation\u001b[39m\u001b[34m(self, messages, stop, run_manager, verbose, **kwargs)\u001b[39m\n\u001b[32m    951\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_chat_stream_with_aggregation\u001b[39m(\n\u001b[32m    952\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    953\u001b[39m     messages: \u001b[38;5;28mlist\u001b[39m[BaseMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m    957\u001b[39m     **kwargs: Any,\n\u001b[32m    958\u001b[39m ) -> ChatGenerationChunk:\n\u001b[32m    959\u001b[39m     final_chunk = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m960\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iterate_over_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfinal_chunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfinal_chunk\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Langgraph\\venv\\Lib\\site-packages\\langchain_ollama\\chat_models.py:1049\u001b[39m, in \u001b[36mChatOllama._iterate_over_stream\u001b[39m\u001b[34m(self, messages, stop, **kwargs)\u001b[39m\n\u001b[32m   1042\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_iterate_over_stream\u001b[39m(\n\u001b[32m   1043\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1044\u001b[39m     messages: \u001b[38;5;28mlist\u001b[39m[BaseMessage],\n\u001b[32m   1045\u001b[39m     stop: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1046\u001b[39m     **kwargs: Any,\n\u001b[32m   1047\u001b[39m ) -> Iterator[ChatGenerationChunk]:\n\u001b[32m   1048\u001b[39m     reasoning = kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mreasoning\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m.reasoning)\n\u001b[32m-> \u001b[39m\u001b[32m1049\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_chat_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1050\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1051\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1052\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessage\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessage\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessage\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   1054\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   1055\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Langgraph\\venv\\Lib\\site-packages\\langchain_ollama\\chat_models.py:947\u001b[39m, in \u001b[36mChatOllama._create_chat_stream\u001b[39m\u001b[34m(self, messages, stop, **kwargs)\u001b[39m\n\u001b[32m    945\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chat_params[\u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    946\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client:\n\u001b[32m--> \u001b[39m\u001b[32m947\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client.chat(**chat_params)\n\u001b[32m    948\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client:\n\u001b[32m    949\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client.chat(**chat_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Langgraph\\venv\\Lib\\site-packages\\ollama\\_client.py:179\u001b[39m, in \u001b[36mClient._request.<locals>.inner\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.HTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    178\u001b[39m   e.response.read()\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ResponseError(e.response.text, e.response.status_code) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m r.iter_lines():\n\u001b[32m    182\u001b[39m   part = json.loads(line)\n",
      "\u001b[31mResponseError\u001b[39m: Invalid tool usage: mismatch between tool calls and tool results (status code: 400)",
      "During task with name 'llm_agent' and id '9e7a6535-2d17-71d0-3400-f0aa55cff0b5'"
     ]
    }
   ],
   "source": [
    "# 1Ô∏è‚É£ Imports \n",
    "from langchain.tools import tool\n",
    "from langchain_community.tools import DuckDuckGoSearchRun, WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from typing import TypedDict\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from sympy import symbols, sympify, diff, integrate, limit, solve\n",
    "from langchain.tools import tool\n",
    "\n",
    "# 2Ô∏è‚É£ Define Graph State\n",
    "class GraphState(TypedDict):\n",
    "    messages: list\n",
    "    tool_call: dict | None\n",
    "\n",
    "# 3Ô∏è‚É£ Tools\n",
    "@tool\n",
    "def math_tool(expression: str, operation: str = \"evaluate\") -> str:\n",
    "    \"\"\"\n",
    "    Powerful symbolic mathematics tool using SymPy.\n",
    "\n",
    "    - operation=\"evaluate\" ‚Üí evaluates arithmetic expression\n",
    "    - operation=\"differentiate\" ‚Üí differentiation wrt x\n",
    "    - operation=\"integrate\" ‚Üí indefinite integral wrt x\n",
    "    - operation=\"limit\" ‚Üí compute limit as x‚Üí0 (default)\n",
    "    - operation=\"solve\" ‚Üí solve equation (set expression = 0)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        x = symbols('x')\n",
    "        expr = sympify(expression)\n",
    "\n",
    "        if operation == \"evaluate\":\n",
    "            return str(expr)\n",
    "\n",
    "        elif operation == \"differentiate\":\n",
    "            return str(diff(expr, x))\n",
    "\n",
    "        elif operation == \"integrate\":\n",
    "            return str(integrate(expr, x))\n",
    "\n",
    "        elif operation == \"limit\":\n",
    "            return str(limit(expr, x, 0))\n",
    "\n",
    "        elif operation == \"solve\":\n",
    "            return str(solve(expr))\n",
    "\n",
    "        else:\n",
    "            return \"Unknown operation.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Math error: {e}\"\n",
    "\n",
    "\n",
    "# üåê Search Tool\n",
    "search_tool = DuckDuckGoSearchRun()\n",
    "\n",
    "# üß† Wikipedia Tool\n",
    "wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper()) # type: ignore\n",
    "\n",
    "# üå§Ô∏è Weather Tool (Free - no key)\n",
    "@tool\n",
    "def weather_tool(city: str) -> str:\n",
    "    \"\"\"Get current weather conditions for any city.\"\"\"\n",
    "    url = f\"https://wttr.in/{city}?format=3\"\n",
    "    try:\n",
    "        return requests.get(url, timeout=5).text\n",
    "    except:\n",
    "        return \"Weather lookup failed.\"\n",
    "\n",
    "# ‚è±Ô∏è Time Tool\n",
    "@tool\n",
    "def time_tool() -> str:\n",
    "    \"\"\"Returns current local time.\"\"\"\n",
    "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "# 4Ô∏è‚É£ LLM + tool binding\n",
    "# llm = ChatOllama(model=\"qwen3:0.6b\")\n",
    "llm = ChatOllama(\n",
    "    model=\"gpt-oss:120b-cloud\"\n",
    ")\n",
    "llm_with_tools = llm.bind_tools([math_tool, search_tool, wikipedia, weather_tool, time_tool])\n",
    "\n",
    "# 5Ô∏è‚É£ LLM Node\n",
    "def llm_agent(state: GraphState):\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    tool_call = getattr(response, \"tool_calls\", None)\n",
    "    return {\"messages\": state[\"messages\"] + [response], \"tool_call\": tool_call}\n",
    "\n",
    "# 6Ô∏è‚É£ Tool Node\n",
    "tool_node = ToolNode([math_tool, search_tool, wikipedia, weather_tool, time_tool])\n",
    "\n",
    "# 7Ô∏è‚É£ Router\n",
    "\n",
    "def route_to_tool_or_end(state: GraphState) -> str:\n",
    "    if state.get(\"tool_call\"):\n",
    "        return \"tool_executor\"\n",
    "    else:\n",
    "        return \"final_answer\"\n",
    "\n",
    "def final_answer(state: GraphState):\n",
    "    \"\"\"Summarize all messages into a final human-friendly response.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    text = \"\"\n",
    "\n",
    "    for msg in messages:\n",
    "        if hasattr(msg, \"content\") and msg.content:\n",
    "            text += f\"{msg.content}\\n\"\n",
    "\n",
    "    return {\"messages\": messages + [text], \"tool_call\": None}\n",
    "\n",
    "# 8Ô∏è‚É£ Build Workflow\n",
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node(\"llm_agent\", llm_agent)\n",
    "workflow.add_node(\"tool_executor\", tool_node)\n",
    "workflow.add_node(\"final_answer\", final_answer)\n",
    "workflow.set_entry_point(\"llm_agent\")\n",
    "\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"llm_agent\",\n",
    "    route_to_tool_or_end,\n",
    "    {\n",
    "        \"tool_executor\": \"tool_executor\",\n",
    "        \"final_answer\": \"final_answer\"\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"tool_executor\", \"llm_agent\")\n",
    "workflow.add_edge(\"final_answer\", END)\n",
    "\n",
    "\n",
    "\n",
    "# 9Ô∏è‚É£ Compile\n",
    "app = workflow.compile()\n",
    "\n",
    "# üîü Run Example\n",
    "result = app.invoke({\"messages\": [\"What's the weather in Mumbai and what is 12*8? Also tell time now.\"]}) # type: ignore\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8987a605",
   "metadata": {},
   "outputs": [
    {
     "ename": "ResponseError",
     "evalue": "Invalid tool usage: mismatch between tool calls and tool results (status code: 400)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mResponseError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 154\u001b[39m\n\u001b[32m    151\u001b[39m app = workflow.compile()\n\u001b[32m    153\u001b[39m \u001b[38;5;66;03m# üîü Run Example\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m result = \u001b[43mapp\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWhat\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43ms the weather in Mumbai and what is 12*8? Also tell time now.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    155\u001b[39m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Langgraph\\venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:3094\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3091\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3092\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3094\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3095\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3096\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3097\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3098\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3099\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3100\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3101\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3102\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3103\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3104\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3105\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3106\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3107\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3108\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3109\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Langgraph\\venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:2679\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2677\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2678\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2679\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2680\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2681\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2682\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2683\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2684\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2685\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2686\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2687\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2688\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2689\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Langgraph\\venv\\Lib\\site-packages\\langgraph\\pregel\\_runner.py:167\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    165\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Langgraph\\venv\\Lib\\site-packages\\langgraph\\pregel\\_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Langgraph\\venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:656\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    654\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    658\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Langgraph\\venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:400\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    398\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 89\u001b[39m, in \u001b[36mllm_agent\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mllm_agent\u001b[39m(state: GraphState):\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m     response = \u001b[43mllm_with_tools\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     90\u001b[39m     tool_call = \u001b[38;5;28mgetattr\u001b[39m(response, \u001b[33m\"\u001b[39m\u001b[33mtool_calls\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     91\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: state[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m] + [response], \u001b[33m\"\u001b[39m\u001b[33mtool_call\u001b[39m\u001b[33m\"\u001b[39m: tool_call}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Langgraph\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5492\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5485\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5486\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5487\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5490\u001b[39m     **kwargs: Any | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   5491\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5492\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5493\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5494\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5495\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5496\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Langgraph\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:379\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    365\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    366\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    367\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    372\u001b[39m     **kwargs: Any,\n\u001b[32m    373\u001b[39m ) -> AIMessage:\n\u001b[32m    374\u001b[39m     config = ensure_config(config)\n\u001b[32m    375\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    376\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    377\u001b[39m         cast(\n\u001b[32m    378\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m379\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    389\u001b[39m         ).message,\n\u001b[32m    390\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Langgraph\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1088\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1079\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1080\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1081\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1085\u001b[39m     **kwargs: Any,\n\u001b[32m   1086\u001b[39m ) -> LLMResult:\n\u001b[32m   1087\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1088\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Langgraph\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:903\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    900\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    901\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    902\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m903\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    904\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    905\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    906\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    907\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    908\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    909\u001b[39m         )\n\u001b[32m    910\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    911\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Langgraph\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1192\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1190\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1191\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1192\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1196\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Langgraph\\venv\\Lib\\site-packages\\langchain_ollama\\chat_models.py:1025\u001b[39m, in \u001b[36mChatOllama._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1018\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate\u001b[39m(\n\u001b[32m   1019\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1020\u001b[39m     messages: \u001b[38;5;28mlist\u001b[39m[BaseMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1023\u001b[39m     **kwargs: Any,\n\u001b[32m   1024\u001b[39m ) -> ChatResult:\n\u001b[32m-> \u001b[39m\u001b[32m1025\u001b[39m     final_chunk = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_chat_stream_with_aggregation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1028\u001b[39m     generation_info = final_chunk.generation_info\n\u001b[32m   1029\u001b[39m     chat_generation = ChatGeneration(\n\u001b[32m   1030\u001b[39m         message=AIMessage(\n\u001b[32m   1031\u001b[39m             content=final_chunk.text,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1038\u001b[39m         generation_info=generation_info,\n\u001b[32m   1039\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Langgraph\\venv\\Lib\\site-packages\\langchain_ollama\\chat_models.py:960\u001b[39m, in \u001b[36mChatOllama._chat_stream_with_aggregation\u001b[39m\u001b[34m(self, messages, stop, run_manager, verbose, **kwargs)\u001b[39m\n\u001b[32m    951\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_chat_stream_with_aggregation\u001b[39m(\n\u001b[32m    952\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    953\u001b[39m     messages: \u001b[38;5;28mlist\u001b[39m[BaseMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m    957\u001b[39m     **kwargs: Any,\n\u001b[32m    958\u001b[39m ) -> ChatGenerationChunk:\n\u001b[32m    959\u001b[39m     final_chunk = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m960\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iterate_over_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfinal_chunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfinal_chunk\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Langgraph\\venv\\Lib\\site-packages\\langchain_ollama\\chat_models.py:1049\u001b[39m, in \u001b[36mChatOllama._iterate_over_stream\u001b[39m\u001b[34m(self, messages, stop, **kwargs)\u001b[39m\n\u001b[32m   1042\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_iterate_over_stream\u001b[39m(\n\u001b[32m   1043\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1044\u001b[39m     messages: \u001b[38;5;28mlist\u001b[39m[BaseMessage],\n\u001b[32m   1045\u001b[39m     stop: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1046\u001b[39m     **kwargs: Any,\n\u001b[32m   1047\u001b[39m ) -> Iterator[ChatGenerationChunk]:\n\u001b[32m   1048\u001b[39m     reasoning = kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mreasoning\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m.reasoning)\n\u001b[32m-> \u001b[39m\u001b[32m1049\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_chat_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1050\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1051\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1052\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessage\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessage\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessage\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   1054\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   1055\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Langgraph\\venv\\Lib\\site-packages\\langchain_ollama\\chat_models.py:947\u001b[39m, in \u001b[36mChatOllama._create_chat_stream\u001b[39m\u001b[34m(self, messages, stop, **kwargs)\u001b[39m\n\u001b[32m    945\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chat_params[\u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    946\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client:\n\u001b[32m--> \u001b[39m\u001b[32m947\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client.chat(**chat_params)\n\u001b[32m    948\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client:\n\u001b[32m    949\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client.chat(**chat_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Langgraph\\venv\\Lib\\site-packages\\ollama\\_client.py:179\u001b[39m, in \u001b[36mClient._request.<locals>.inner\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.HTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    178\u001b[39m   e.response.read()\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ResponseError(e.response.text, e.response.status_code) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m r.iter_lines():\n\u001b[32m    182\u001b[39m   part = json.loads(line)\n",
      "\u001b[31mResponseError\u001b[39m: Invalid tool usage: mismatch between tool calls and tool results (status code: 400)",
      "During task with name 'llm_agent' and id '6bff9edf-c35d-5637-3229-01c6e5ea7cac'"
     ]
    }
   ],
   "source": [
    "# 1Ô∏è‚É£ Imports \n",
    "from langchain.tools import tool\n",
    "from langchain_community.tools import DuckDuckGoSearchRun, WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from typing import TypedDict\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from sympy import symbols, sympify, diff, integrate, limit, solve\n",
    "from langchain.tools import tool\n",
    "\n",
    "# 2Ô∏è‚É£ Define Graph State\n",
    "class GraphState(TypedDict):\n",
    "    messages: list\n",
    "    tool_call: dict | None\n",
    "\n",
    "# 3Ô∏è‚É£ Tools\n",
    "@tool\n",
    "def math_tool(expression: str, operation: str = \"evaluate\") -> str:\n",
    "    \"\"\"\n",
    "    Powerful symbolic mathematics tool using SymPy.\n",
    "\n",
    "    - operation=\"evaluate\" ‚Üí evaluates arithmetic expression\n",
    "    - operation=\"differentiate\" ‚Üí differentiation wrt x\n",
    "    - operation=\"integrate\" ‚Üí indefinite integral wrt x\n",
    "    - operation=\"limit\" ‚Üí compute limit as x‚Üí0 (default)\n",
    "    - operation=\"solve\" ‚Üí solve equation (set expression = 0)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        x = symbols('x')\n",
    "        expr = sympify(expression)\n",
    "\n",
    "        if operation == \"evaluate\":\n",
    "            return str(expr)\n",
    "\n",
    "        elif operation == \"differentiate\":\n",
    "            return str(diff(expr, x))\n",
    "\n",
    "        elif operation == \"integrate\":\n",
    "            return str(integrate(expr, x))\n",
    "\n",
    "        elif operation == \"limit\":\n",
    "            return str(limit(expr, x, 0))\n",
    "\n",
    "        elif operation == \"solve\":\n",
    "            return str(solve(expr))\n",
    "\n",
    "        else:\n",
    "            return \"Unknown operation.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Math error: {e}\"\n",
    "\n",
    "\n",
    "# üåê Search Tool\n",
    "search_tool = DuckDuckGoSearchRun()\n",
    "\n",
    "# üß† Wikipedia Tool\n",
    "wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper()) # type: ignore\n",
    "\n",
    "# üå§Ô∏è Weather Tool (Free - no key)\n",
    "@tool\n",
    "def weather_tool(city: str) -> str:\n",
    "    \"\"\"Get current weather conditions for any city.\"\"\"\n",
    "    url = f\"https://wttr.in/{city}?format=3\"\n",
    "    try:\n",
    "        return requests.get(url, timeout=5).text\n",
    "    except:\n",
    "        return \"Weather lookup failed.\"\n",
    "\n",
    "# ‚è±Ô∏è Time Tool\n",
    "@tool\n",
    "def time_tool() -> str:\n",
    "    \"\"\"Returns current local time.\"\"\"\n",
    "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "# 4Ô∏è‚É£ LLM + tool binding\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"gpt-oss:120b-cloud\"\n",
    ")\n",
    "\n",
    "llm_with_tools = llm.bind_tools([math_tool, search_tool, wikipedia, weather_tool, time_tool])\n",
    "\n",
    "# 5Ô∏è‚É£ LLM Node\n",
    "def llm_agent(state: GraphState):\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    tool_call = getattr(response, \"tool_calls\", None)\n",
    "    return {\"messages\": state[\"messages\"] + [response], \"tool_call\": tool_call}\n",
    "\n",
    "# 6Ô∏è‚É£ Tool Node\n",
    "tool_node = ToolNode([math_tool, search_tool, wikipedia, weather_tool, time_tool])\n",
    "\n",
    "# 7Ô∏è‚É£ Router\n",
    "# def route_to_tool_or_end(state: GraphState) -> str:\n",
    "#     return \"tool_executor\" if state.get(\"tool_call\") else END\n",
    "\n",
    "def route_to_tool_or_end(state: GraphState) -> str:\n",
    "    if state.get(\"tool_call\"):\n",
    "        return \"tool_executor\"\n",
    "    else:\n",
    "        return \"final_answer\"\n",
    "\n",
    "def final_answer(state: GraphState):\n",
    "    \"\"\"Summarize all messages into a final human-friendly response.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    text = \"\"\n",
    "\n",
    "    for msg in messages:\n",
    "        if hasattr(msg, \"content\") and msg.content:\n",
    "            text += f\"{msg.content}\\n\"\n",
    "\n",
    "    return {\"messages\": messages + [text], \"tool_call\": None}\n",
    "\n",
    "# 8Ô∏è‚É£ Build Workflow\n",
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node(\"llm_agent\", llm_agent)\n",
    "workflow.add_node(\"tool_executor\", tool_node)\n",
    "workflow.add_node(\"final_answer\", final_answer)\n",
    "workflow.set_entry_point(\"llm_agent\")\n",
    "\n",
    "# workflow.add_conditional_edges(\n",
    "#     \"llm_agent\", route_to_tool_or_end,\n",
    "#     {\"tool_executor\": \"tool_executor\", END: END}\n",
    "# )\n",
    "# workflow.add_conditional_edges(\n",
    "#     \"llm_agent\", route_to_tool_or_end,\n",
    "#     {\"tool_executor\": \"tool_executor\", \"final_answer\": \"final_answer\"}\n",
    "# )\n",
    "\n",
    "# workflow.add_edge(\"tool_executor\", \"llm_agent\")\n",
    "# workflow.add_edge(\"final_answer\", END)\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"llm_agent\",\n",
    "    route_to_tool_or_end,\n",
    "    {\n",
    "        \"tool_executor\": \"tool_executor\",\n",
    "        \"final_answer\": \"final_answer\"\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"tool_executor\", \"llm_agent\")\n",
    "workflow.add_edge(\"final_answer\", END)\n",
    "\n",
    "\n",
    "\n",
    "# 9Ô∏è‚É£ Compile\n",
    "app = workflow.compile()\n",
    "\n",
    "# üîü Run Example\n",
    "result = app.invoke({\"messages\": [\"What's the weather in Mumbai and what is 12*8? Also tell time now.\"]}) # type: ignore\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a8a97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1Ô∏è‚É£ Imports \n",
    "from langchain.tools import tool\n",
    "from langchain_core.tools import Tool\n",
    "from langchain_community.tools import DuckDuckGoSearchRun, WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from typing import TypedDict\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from sympy import symbols, sympify, diff, integrate, limit, solve\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# ------------------ HUGGINGFACE MODEL -----------------\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"gpt-oss:120b-cloud\"\n",
    ")\n",
    "\n",
    "\n",
    "# 2Ô∏è‚É£ Graph State\n",
    "class GraphState(TypedDict):\n",
    "    messages: list\n",
    "    tool_call: dict | None\n",
    "\n",
    "\n",
    "# 3Ô∏è‚É£ Math Tool\n",
    "from langchain.tools import tool\n",
    "from sympy import symbols, sympify, diff, integrate\n",
    "\n",
    "# 3Ô∏è‚É£ Math Tool\n",
    "@tool\n",
    "def math_tool(expression: str, operation: str = \"evaluate\") -> str:\n",
    "    \"\"\"\n",
    "    A math tool that can evaluate or differentiate or integrate symbolic expressions.\n",
    "    \n",
    "    Args:\n",
    "        expression (str): The mathematical expression (e.g. \"x^2 + 3*x\")\n",
    "        operation (str): One of [\"evaluate\", \"differentiate\", \"integrate\"]\n",
    "    \n",
    "    Returns:\n",
    "        str: The result of the mathematical operation.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        x = symbols('x')\n",
    "        expr = sympify(expression.replace(\"^\", \"**\"))\n",
    "\n",
    "        if operation == \"evaluate\":\n",
    "            return str(expr)\n",
    "\n",
    "        elif operation == \"differentiate\":\n",
    "            return str(diff(expr, x))\n",
    "\n",
    "        elif operation == \"integrate\":\n",
    "            return str(integrate(expr, x))\n",
    "\n",
    "        else:\n",
    "            return \"‚ùå Invalid operation. Use: evaluate | differentiate | integrate\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Error: {str(e)}\"\n",
    "\n",
    "\n",
    "\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain_community.tools import WikipediaQueryRun\n",
    "\n",
    "@tool\n",
    "def web_search(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Search the internet using DuckDuckGo and return summary results.\n",
    "    \"\"\"\n",
    "    search = DuckDuckGoSearchRun()\n",
    "    return search.run(query)\n",
    "\n",
    "@tool\n",
    "def wiki_search(topic: str) -> str:\n",
    "    \"\"\"\n",
    "    Search Wikipedia and return a short summary of a topic.\n",
    "    \"\"\"\n",
    "    wiki = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper()) # type: ignore\n",
    "    return wiki.run(topic)\n",
    "\n",
    "\n",
    "\n",
    "# 5Ô∏è‚É£ Weather Tool\n",
    "@tool\n",
    "def weather_tool(city: str) -> str:\n",
    "    \"\"\"\n",
    "    Get the current weather for a specified city.\n",
    "    \"\"\" # <--- ADDED DOCSTRING HERE\n",
    "    url = f\"https://wttr.in/{city}?format=3\"\n",
    "    try:\n",
    "        return requests.get(url, timeout=5).text\n",
    "    except:\n",
    "        return \"Weather lookup failed.\"\n",
    "\n",
    "# 6Ô∏è‚É£ Time Tool\n",
    "@tool\n",
    "def time_tool() -> str:\n",
    "    \"\"\"\n",
    "    Returns the current date and time in YYYY-MM-DD HH:MM:SS format.\n",
    "    \"\"\" # <--- ADDED DOCSTRING HERE\n",
    "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "\n",
    "# 7Ô∏è‚É£ Bind Tools to Model and Tool Node\n",
    "tools = [math_tool, web_search, wiki_search, weather_tool, time_tool]\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "# 8Ô∏è‚É£ LLM Node\n",
    "def llm_agent(state: GraphState):\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    tool_call = getattr(response, \"tool_calls\", None)\n",
    "    return {\"messages\": state[\"messages\"] + [response], \"tool_call\": tool_call}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# üîü Router\n",
    "def route_to_tool_or_end(state: GraphState) -> str:\n",
    "    return \"tool_executor\" if state.get(\"tool_call\") else \"final_answer\"\n",
    "\n",
    "\n",
    "# 1Ô∏è‚É£1Ô∏è‚É£ Final response node\n",
    "\n",
    "def final_answer(state: GraphState):\n",
    "    msgs = state[\"messages\"]\n",
    "    last_ai = next((m for m in reversed(msgs) if isinstance(m, AIMessage)), None)\n",
    "    content = last_ai.content if last_ai else \"Done.\"\n",
    "    return {\"messages\": msgs + [AIMessage(content=content)], \"tool_call\": None}\n",
    "\n",
    "\n",
    "\n",
    "# 1Ô∏è‚É£2Ô∏è‚É£ Graph\n",
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node(\"llm_agent\", llm_agent)\n",
    "workflow.add_node(\"tool_executor\", tool_node)\n",
    "workflow.add_node(\"final_answer\", final_answer)\n",
    "workflow.set_entry_point(\"llm_agent\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"llm_agent\",\n",
    "    route_to_tool_or_end,\n",
    "    {\"tool_executor\": \"tool_executor\", \"final_answer\": \"final_answer\"}\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"tool_executor\", \"llm_agent\")\n",
    "workflow.add_edge(\"final_answer\", END)\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "\n",
    "# 1Ô∏è‚É£3Ô∏è‚É£ Test Run\n",
    "result = app.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"What's the weather in Mumbai and 12*8 and the time?\")]\n",
    "}) # type: ignore\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47266a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wikipedia in c:\\langgraph\\venv\\lib\\site-packages (1.4.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\langgraph\\venv\\lib\\site-packages (from wikipedia) (4.14.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\langgraph\\venv\\lib\\site-packages (from wikipedia) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\langgraph\\venv\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\langgraph\\venv\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\langgraph\\venv\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\langgraph\\venv\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2025.10.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\langgraph\\venv\\lib\\site-packages (from beautifulsoup4->wikipedia) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\langgraph\\venv\\lib\\site-packages (from beautifulsoup4->wikipedia) (4.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24fe411e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ResponseError",
     "evalue": "Invalid tool usage: mismatch between tool calls and tool results (status code: 400)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mResponseError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 171\u001b[39m\n\u001b[32m    168\u001b[39m app = workflow.compile()\n\u001b[32m    170\u001b[39m \u001b[38;5;66;03m# üîü Run Example\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m result = \u001b[43mapp\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWhat\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43ms the weather in Mumbai and what is 12*8? Also tell time now.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    172\u001b[39m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Langgraph\\venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:3094\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3091\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3092\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3094\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3095\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3096\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3097\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3098\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3099\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3100\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3101\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3102\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3103\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3104\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3105\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3106\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3107\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3108\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3109\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Langgraph\\venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:2679\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2677\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2678\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2679\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2680\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2681\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2682\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2683\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2684\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2685\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2686\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2687\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2688\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2689\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Langgraph\\venv\\Lib\\site-packages\\langgraph\\pregel\\_runner.py:167\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    165\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Langgraph\\venv\\Lib\\site-packages\\langgraph\\pregel\\_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Langgraph\\venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:656\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    654\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    658\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Langgraph\\venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:400\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    398\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 92\u001b[39m, in \u001b[36mllm_agent\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mllm_agent\u001b[39m(state: GraphState):\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     response = \u001b[43mllm_with_tools\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     93\u001b[39m     tool_call = \u001b[38;5;28mgetattr\u001b[39m(response, \u001b[33m\"\u001b[39m\u001b[33mtool_calls\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: state[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m] + [response], \u001b[33m\"\u001b[39m\u001b[33mtool_call\u001b[39m\u001b[33m\"\u001b[39m: tool_call}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Langgraph\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5492\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5485\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5486\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5487\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5490\u001b[39m     **kwargs: Any | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   5491\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5492\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5493\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5494\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5495\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5496\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Langgraph\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:379\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    365\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    366\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    367\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    372\u001b[39m     **kwargs: Any,\n\u001b[32m    373\u001b[39m ) -> AIMessage:\n\u001b[32m    374\u001b[39m     config = ensure_config(config)\n\u001b[32m    375\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    376\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    377\u001b[39m         cast(\n\u001b[32m    378\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m379\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    389\u001b[39m         ).message,\n\u001b[32m    390\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Langgraph\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1088\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1079\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1080\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1081\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1085\u001b[39m     **kwargs: Any,\n\u001b[32m   1086\u001b[39m ) -> LLMResult:\n\u001b[32m   1087\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1088\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Langgraph\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:903\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    900\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    901\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    902\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m903\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    904\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    905\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    906\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    907\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    908\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    909\u001b[39m         )\n\u001b[32m    910\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    911\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Langgraph\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1192\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1190\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1191\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1192\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1196\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Langgraph\\venv\\Lib\\site-packages\\langchain_ollama\\chat_models.py:1025\u001b[39m, in \u001b[36mChatOllama._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1018\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate\u001b[39m(\n\u001b[32m   1019\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1020\u001b[39m     messages: \u001b[38;5;28mlist\u001b[39m[BaseMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1023\u001b[39m     **kwargs: Any,\n\u001b[32m   1024\u001b[39m ) -> ChatResult:\n\u001b[32m-> \u001b[39m\u001b[32m1025\u001b[39m     final_chunk = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_chat_stream_with_aggregation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1028\u001b[39m     generation_info = final_chunk.generation_info\n\u001b[32m   1029\u001b[39m     chat_generation = ChatGeneration(\n\u001b[32m   1030\u001b[39m         message=AIMessage(\n\u001b[32m   1031\u001b[39m             content=final_chunk.text,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1038\u001b[39m         generation_info=generation_info,\n\u001b[32m   1039\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Langgraph\\venv\\Lib\\site-packages\\langchain_ollama\\chat_models.py:960\u001b[39m, in \u001b[36mChatOllama._chat_stream_with_aggregation\u001b[39m\u001b[34m(self, messages, stop, run_manager, verbose, **kwargs)\u001b[39m\n\u001b[32m    951\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_chat_stream_with_aggregation\u001b[39m(\n\u001b[32m    952\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    953\u001b[39m     messages: \u001b[38;5;28mlist\u001b[39m[BaseMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m    957\u001b[39m     **kwargs: Any,\n\u001b[32m    958\u001b[39m ) -> ChatGenerationChunk:\n\u001b[32m    959\u001b[39m     final_chunk = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m960\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iterate_over_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfinal_chunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfinal_chunk\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Langgraph\\venv\\Lib\\site-packages\\langchain_ollama\\chat_models.py:1049\u001b[39m, in \u001b[36mChatOllama._iterate_over_stream\u001b[39m\u001b[34m(self, messages, stop, **kwargs)\u001b[39m\n\u001b[32m   1042\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_iterate_over_stream\u001b[39m(\n\u001b[32m   1043\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1044\u001b[39m     messages: \u001b[38;5;28mlist\u001b[39m[BaseMessage],\n\u001b[32m   1045\u001b[39m     stop: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1046\u001b[39m     **kwargs: Any,\n\u001b[32m   1047\u001b[39m ) -> Iterator[ChatGenerationChunk]:\n\u001b[32m   1048\u001b[39m     reasoning = kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mreasoning\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m.reasoning)\n\u001b[32m-> \u001b[39m\u001b[32m1049\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_chat_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1050\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1051\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1052\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessage\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessage\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessage\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   1054\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   1055\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Langgraph\\venv\\Lib\\site-packages\\langchain_ollama\\chat_models.py:947\u001b[39m, in \u001b[36mChatOllama._create_chat_stream\u001b[39m\u001b[34m(self, messages, stop, **kwargs)\u001b[39m\n\u001b[32m    945\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chat_params[\u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    946\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client:\n\u001b[32m--> \u001b[39m\u001b[32m947\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client.chat(**chat_params)\n\u001b[32m    948\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client:\n\u001b[32m    949\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client.chat(**chat_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Langgraph\\venv\\Lib\\site-packages\\ollama\\_client.py:179\u001b[39m, in \u001b[36mClient._request.<locals>.inner\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.HTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    178\u001b[39m   e.response.read()\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ResponseError(e.response.text, e.response.status_code) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m r.iter_lines():\n\u001b[32m    182\u001b[39m   part = json.loads(line)\n",
      "\u001b[31mResponseError\u001b[39m: Invalid tool usage: mismatch between tool calls and tool results (status code: 400)",
      "During task with name 'llm_agent' and id '52396486-cef4-31b9-935d-84050c6efe4e'"
     ]
    }
   ],
   "source": [
    "# 1Ô∏è‚É£ Imports \n",
    "from langchain.tools import tool\n",
    "from langchain_community.tools import DuckDuckGoSearchRun, WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from typing import TypedDict\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from sympy import symbols, sympify, diff, integrate, limit, solve\n",
    "from langchain.tools import tool\n",
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "\n",
    "# 2Ô∏è‚É£ Define Graph State\n",
    "class GraphState(TypedDict):\n",
    "    messages: list\n",
    "    tool_call: dict | None\n",
    "\n",
    "# 3Ô∏è‚É£ Tools\n",
    "@tool\n",
    "def math_tool(expression: str, operation: str = \"evaluate\") -> str:\n",
    "    \"\"\"\n",
    "    Powerful symbolic mathematics tool using SymPy.\n",
    "\n",
    "    - operation=\"evaluate\" ‚Üí evaluates arithmetic expression\n",
    "    - operation=\"differentiate\" ‚Üí differentiation wrt x\n",
    "    - operation=\"integrate\" ‚Üí indefinite integral wrt x\n",
    "    - operation=\"limit\" ‚Üí compute limit as x‚Üí0 (default)\n",
    "    - operation=\"solve\" ‚Üí solve equation (set expression = 0)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        x = symbols('x')\n",
    "        expr = sympify(expression)\n",
    "\n",
    "        if operation == \"evaluate\":\n",
    "            return str(expr)\n",
    "\n",
    "        elif operation == \"differentiate\":\n",
    "            return str(diff(expr, x))\n",
    "\n",
    "        elif operation == \"integrate\":\n",
    "            return str(integrate(expr, x))\n",
    "\n",
    "        elif operation == \"limit\":\n",
    "            return str(limit(expr, x, 0))\n",
    "\n",
    "        elif operation == \"solve\":\n",
    "            return str(solve(expr))\n",
    "\n",
    "        else:\n",
    "            return \"Unknown operation.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Math error: {e}\"\n",
    "\n",
    "\n",
    "# üåê Search Tool\n",
    "search_tool = DuckDuckGoSearchRun()\n",
    "\n",
    "# üß† Wikipedia Tool\n",
    "wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper()) # type: ignore\n",
    "\n",
    "# üå§Ô∏è Weather Tool (Free - no key)\n",
    "@tool\n",
    "def weather_tool(city: str) -> str:\n",
    "    \"\"\"Get current weather conditions for any city.\"\"\"\n",
    "    url = f\"https://wttr.in/{city}?format=3\"\n",
    "    try:\n",
    "        return requests.get(url, timeout=5).text\n",
    "    except:\n",
    "        return \"Weather lookup failed.\"\n",
    "\n",
    "# ‚è±Ô∏è Time Tool\n",
    "@tool\n",
    "def time_tool() -> str:\n",
    "    \"\"\"Returns current local time.\"\"\"\n",
    "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "# 4Ô∏è‚É£ LLM + tool binding\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"gpt-oss:120b-cloud\"\n",
    ")\n",
    "llm_with_tools = llm.bind_tools([math_tool, search_tool, wikipedia, weather_tool, time_tool])\n",
    "\n",
    "# 5Ô∏è‚É£ LLM Node\n",
    "def llm_agent(state: GraphState):\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    tool_call = getattr(response, \"tool_calls\", None)\n",
    "    return {\"messages\": state[\"messages\"] + [response], \"tool_call\": tool_call}\n",
    "\n",
    "# 6Ô∏è‚É£ Tool Node\n",
    "tool_node = ToolNode([math_tool, search_tool, wikipedia, weather_tool, time_tool])\n",
    "\n",
    "# 7Ô∏è‚É£ Router\n",
    "\n",
    "def route_to_tool_or_end(state: GraphState) -> str:\n",
    "    if state.get(\"tool_call\"):\n",
    "        return \"tool_executor\"\n",
    "    else:\n",
    "        return \"final_answer\"\n",
    "\n",
    "\n",
    "def final_answer(state: GraphState):\n",
    "    \"\"\"Summarize all tool outputs into a clean human-readable answer.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    weather = None\n",
    "    math = None\n",
    "    time = None\n",
    "    wiki = None\n",
    "\n",
    "    for msg in messages:\n",
    "        if hasattr(msg, \"name\"):\n",
    "            if msg.name == \"weather_tool\":\n",
    "                weather = msg.content.strip()\n",
    "            elif msg.name == \"math_tool\":\n",
    "                math = msg.content.strip()\n",
    "            elif msg.name == \"time_tool\":\n",
    "                time = msg.content.strip()\n",
    "            elif msg.name == \"wikipedia_query_run\":\n",
    "                wiki = msg.content.strip()\n",
    "\n",
    "    final_reply = \"Here are the results:\\n\\n\"\n",
    "\n",
    "    if weather:\n",
    "        final_reply += f\"üå§ **Weather:** {weather}\\n\"\n",
    "    if math:\n",
    "        final_reply += f\"üßÆ **Math Result:** {math}\\n\"\n",
    "    if time:\n",
    "        final_reply += f\"‚è± **Current Time:** {time}\\n\"\n",
    "    if wiki:\n",
    "        final_reply += f\"üìò **Wikipedia Info:**\\n{wiki}\\n\"\n",
    "\n",
    "    return {\n",
    "        \"messages\": messages + [AIMessage(content=final_reply)],\n",
    "        \"tool_call\": None\n",
    "    }\n",
    "\n",
    "\n",
    "# 8Ô∏è‚É£ Build Workflow\n",
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node(\"llm_agent\", llm_agent)\n",
    "workflow.add_node(\"tool_executor\", tool_node)\n",
    "workflow.add_node(\"final_answer\", final_answer)\n",
    "workflow.set_entry_point(\"llm_agent\")\n",
    "\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"llm_agent\",\n",
    "    route_to_tool_or_end,\n",
    "    {\n",
    "        \"tool_executor\": \"tool_executor\",\n",
    "        \"final_answer\": \"final_answer\"\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"tool_executor\", \"llm_agent\")\n",
    "workflow.add_edge(\"final_answer\", END)\n",
    "\n",
    "\n",
    "\n",
    "# 9Ô∏è‚É£ Compile\n",
    "app = workflow.compile()\n",
    "\n",
    "# üîü Run Example\n",
    "result = app.invoke({\"messages\": [\"What's the weather in Mumbai and what is 12*8? Also tell time now.\"]}) # type: ignore\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02e7fd0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
